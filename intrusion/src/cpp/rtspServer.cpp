#include "rtspServer.h"
#include "jsonlParse.h"

// ----------------------------
// Processing functions
// ----------------------------

bool pushFrame(GstElement *appsrc, StreamContext &ctx)
{
    Mat frame;
    guint64 pts;

    {
        std::lock_guard<std::mutex> lock(frame_mutex);
        if (latest_frame.empty())
        {
            std::cout << "[RTSP] appsrcì— í‘¸ì‰¬ ì•ˆë¨\n";
            return false;
        }

        frame = latest_frame.clone();
        pts = latest_pts;
    }

    // Push to GStreamer appsrc
    int size = frame.total() * frame.elemSize();
    GstBuffer *buf = gst_buffer_new_and_alloc(size);
    GstMapInfo info;
    gst_buffer_map(buf, &info, GST_MAP_WRITE);
    memcpy(info.data, frame.data, size);
    gst_buffer_unmap(buf, &info);

    GST_BUFFER_PTS(buf) = gst_util_uint64_scale(pts, GST_SECOND, ctx.fps);
    GST_BUFFER_DURATION(buf) = gst_util_uint64_scale_int(1, GST_SECOND, ctx.fps);

    GstFlowReturn ret = gst_app_src_push_buffer(GST_APP_SRC(appsrc), buf);
    if (ret != GST_FLOW_OK)
    {
        cerr << "Failed to push buffer to appsrc!" << endl;
        return false;
    }

    return true;
}

static void onNeedData(GstElement *appsrc, guint, gpointer user_data)
{
    StreamContext *ctx = reinterpret_cast<StreamContext *>(user_data);

    if (!running)
    {
        gst_app_src_end_of_stream(GST_APP_SRC(appsrc));
    }
    else
    {
        pushFrame(appsrc, *ctx);
    }
}

bool push_frame_to_appsrc(GstElement *appsrc, const cv::Mat &frame, int fps = 30)
{
    // 1. í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬
    if (frame.empty())
    {
        std::cerr << "[push_frame_to_appsrc] ë¹ˆ í”„ë ˆì„ì…ë‹ˆë‹¤." << std::endl;
        return false;
    }

    // 2. GStreamer ë²„í¼ ìƒì„±
    GstBuffer *buffer = gst_buffer_new_allocate(nullptr, frame.total() * frame.elemSize(), nullptr);
    if (!buffer)
    {
        std::cerr << "[push_frame_to_appsrc] GstBuffer ìƒì„± ì‹¤íŒ¨" << std::endl;
        return false;
    }

    // 3. ë²„í¼ì— ë°ì´í„° ë³µì‚¬
    GstMapInfo map;
    if (!gst_buffer_map(buffer, &map, GST_MAP_WRITE))
    {
        std::cerr << "[push_frame_to_appsrc] ë²„í¼ ë§¤í•‘ ì‹¤íŒ¨" << std::endl;
        gst_buffer_unref(buffer);
        return false;
    }
    memcpy(map.data, frame.data, map.size);
    gst_buffer_unmap(buffer, &map);

    // 4. íƒ€ì„ìŠ¤íƒ¬í”„ ì„¤ì • (appsrcê°€ is-live=true, do-timestamp=trueì¼ ê²½ìš°)
    static GstClockTime pts = 0;
    GST_BUFFER_PTS(buffer) = pts;
    GST_BUFFER_DTS(buffer) = pts;
    GST_BUFFER_DURATION(buffer) = gst_util_uint64_scale_int(1, GST_SECOND, fps);
    pts += GST_BUFFER_DURATION(buffer);

    // 5. appsrcì— í‘¸ì‹œ
    GstFlowReturn ret = gst_app_src_push_buffer(GST_APP_SRC(appsrc), buffer);
    if (ret != GST_FLOW_OK)
    {
        std::cerr << "[push_frame_to_appsrc] ë²„í¼ í‘¸ì‹œ ì‹¤íŒ¨: " << gst_flow_get_name(ret) << std::endl;
        return false;
    }

    return true;
}

static void push_dummy(GstElement *appsrc, StreamContext *ctx)
{
    // Dummy function to ensure appsrc is ready
    // This can be used to push an initial frame if needed

    std::cout << "[RTSP] Dummy push called" << std::endl;

    Mat dummy_frame(ctx->height, ctx->width, CV_8UC3, Scalar(255, 255, 255));
    Mat dummy_frameRGB;
    cvtColor(dummy_frame, dummy_frameRGB, COLOR_BGR2RGB);

    for (int i = 0; i < 5; i++)
    {
        if (!push_frame_to_appsrc(appsrc, dummy_frameRGB))
        {
            std::cerr << "[RTSP] Dummy push failed" << std::endl;
            return;
        }
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
}

// ìƒˆë¡œìš´ ì½œë°± ì¶”ê°€
static void on_media_prepared(GstRTSPMedia *media, gpointer user_data)
{
    StreamContext *ctx = reinterpret_cast<StreamContext *>(user_data);
    GstElement *pipeline = gst_rtsp_media_get_element(media);
    GstElement *appsrc = gst_bin_get_by_name(GST_BIN(pipeline), "video_src");

    std::cout << "[RTSP] Client connected -> pushing dummy frames" << std::endl;

    running = true;
    static std::atomic<bool> dummy_pushed{false};
    if (!dummy_pushed.exchange(true))
    {
        push_dummy(appsrc, ctx);
    }

    gst_object_unref(appsrc);
    gst_object_unref(pipeline);
}

// media_configure ìˆ˜ì •
static void media_configure(GstRTSPMediaFactory *factory, GstRTSPMedia *media, gpointer user_data)
{
    GstElement *pipeline = gst_rtsp_media_get_element(media);
    GstElement *appsrc = gst_bin_get_by_name(GST_BIN(pipeline), "video_src");
    StreamContext *ctx = reinterpret_cast<StreamContext *>(user_data);

    GstCaps *caps = gst_caps_new_simple(
        "video/x-raw",
        "format", G_TYPE_STRING, "BGR",
        "width", G_TYPE_INT, ctx->width,
        "height", G_TYPE_INT, ctx->height,
        "framerate", GST_TYPE_FRACTION, ctx->fps, 1,
        NULL);
    gst_app_src_set_caps(GST_APP_SRC(appsrc), caps);
    gst_caps_unref(caps);

    g_signal_connect(media, "prepared", G_CALLBACK(on_media_prepared), ctx);

    g_signal_connect(appsrc, "need-data", G_CALLBACK(onNeedData), ctx);

    gst_object_unref(appsrc);
    gst_object_unref(pipeline);
}

long calculateBitrate(int width,
                      int height,
                      int fps,
                      double bitsPerPixel = 0.1)
{
    // ì´ˆë‹¹ ì´ í”½ì…€ ìˆ˜ Ã— í”½ì…€ë‹¹ ë¹„íŠ¸ìˆ˜ = ì´ˆë‹¹ ë¹„íŠ¸ ìˆ˜
    double bps = static_cast<double>(width) * height * fps * bitsPerPixel;
    return static_cast<long>(bps);
}

GstRTSPServer *setupRtspServer(StreamContext &ctx)
{
    gst_init(nullptr, nullptr);

    // RTSP ì„œë²„ ìƒì„± ë° í¬íŠ¸ ì„¤ì •
    GstRTSPServer *server = gst_rtsp_server_new();
    g_object_set(server, "service", "8555", NULL);

    // TLS ì¸ì¦ì„œ ë¡œë”©
    GError *error = nullptr;
    GTlsCertificate *cert = g_tls_certificate_new_from_files("server-cert.pem", "server-key.pem", &error);
    if (!cert)
    {
        std::cerr << "TLS ì¸ì¦ì„œ ë¡œë”© ì‹¤íŒ¨: " << error->message << std::endl;
        g_error_free(error);
        return nullptr;
    }

    // ì¸ì¦ ê°ì²´ ìƒì„± ë° ì¸ì¦ì„œ ì„¤ì •
    GstRTSPAuth *auth = gst_rtsp_auth_new();
    gst_rtsp_server_set_auth(server, auth);
    gst_rtsp_auth_set_tls_certificate(auth, cert);

    // default_token ì„¤ì • (ë¹„ë°€ë²ˆí˜¸ ì—†ì´ ì ‘ê·¼ í—ˆìš©)
    GstRTSPToken *token = gst_rtsp_token_new(
        GST_RTSP_TOKEN_MEDIA_FACTORY_ROLE, G_TYPE_STRING, "anonymous", NULL);
    gst_rtsp_auth_set_default_token(auth, token);
    gst_rtsp_token_unref(token);
    g_object_unref(auth);
    g_object_unref(cert);

    // ë¯¸ë””ì–´ factory ì„¤ì •
    GstRTSPMountPoints *mounts = gst_rtsp_server_get_mount_points(server);
    GstRTSPMediaFactory *factory = gst_rtsp_media_factory_new();

    long bitrate = calculateBitrate(ctx.width, ctx.height, ctx.fps, 0.08) / 1000;
    std::string launch_desc =
        "( appsrc name=video_src is-live=true do-timestamp=true format=time "
        "! videoconvert "
        "! video/x-raw,format=NV12 "
        "! v4l2convert "
        "! v4l2h264enc "
        "extra-controls=\"controls,repeat_sequence_header=1,"
        "video_bitrate=" +
        std::to_string(bitrate) +
        ",h264_i_frame_period=1,h264_profile=0\" "
        "! video/x-h264,level=(string)4 "
        "! h264parse "
        "! rtph264pay name=pay0 pt=96 config-interval=1 )";

    gst_rtsp_media_factory_set_launch(factory, launch_desc.c_str());
    gst_rtsp_media_factory_set_shared(factory, TRUE);
    gst_rtsp_media_factory_set_enable_rtcp(factory, TRUE);

    // âœ” appsrc ì½œë°± ì„¤ì •
    g_signal_connect(factory, "media-configure", G_CALLBACK(media_configure), &ctx);

    // ê¶Œí•œ ì„¤ì • (default-permissions ë¯¸ì‚¬ìš©)
    GstRTSPPermissions *fac_perms = gst_rtsp_permissions_new();
    gst_rtsp_permissions_add_role(fac_perms, "anonymous",
                                  GST_RTSP_PERM_MEDIA_FACTORY_ACCESS, G_TYPE_BOOLEAN, TRUE,
                                  GST_RTSP_PERM_MEDIA_FACTORY_CONSTRUCT, G_TYPE_BOOLEAN, TRUE,
                                  NULL);
    gst_rtsp_media_factory_set_permissions(factory, fac_perms);
    gst_rtsp_permissions_unref(fac_perms);

    // mount point ë“±ë¡
    gst_rtsp_mount_points_add_factory(mounts, "/test", factory);
    g_object_unref(mounts);

    // attach
    if (!gst_rtsp_server_attach(server, NULL))
    {
        std::cerr << "RTSP ì„œë²„ attach ì‹¤íŒ¨" << std::endl;
        return nullptr;
    }

    std::cout << "RTSPS ì„œë²„ ì‹¤í–‰ ì¤‘: rtsps://192.168.0.46:8555/test" << std::endl;
    return server;
}

void inferenceLoop(StreamContext *ctx)
{
    while (running)
    {
        Mat frame;
        if (!ctx->cap->read(frame))
        {
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            continue;
        }

        // 1. ì›ë³¸ í”„ë ˆì„ ë³´ê´€
        {
            std::lock_guard<std::mutex> lock(raw_mutex);
            latest_raw_frame = frame.clone();
        }

        // 3. ì†¡ì¶œìš© í”„ë ˆì„ ì„¤ì •
        {
            std::lock_guard<std::mutex> lock(frame_mutex);
            latest_frame = frame.clone();
            latest_pts = ctx->frame_count++;
        }

        std::this_thread::sleep_for(std::chrono::milliseconds(1000 / ctx->fps));
    }
}

void detectionLoop(StreamContext *ctx)
{
    initMotionDetector();

    std::map<int, DetectionResult> tracked;
    std::map<int, int> appearCount;
    int next_id = 0;
    bool prev_had_motion = false;  // ğŸ”¸ ì´ì „ í”„ë ˆì„ì— ê°ì§€ëœ ê°ì²´ê°€ ìˆì—ˆëŠ”ì§€

    while (running)
    {
        Mat raw_frame;
        {
            std::lock_guard<std::mutex> lock(raw_mutex);
            if (latest_raw_frame.empty())
                continue;
            raw_frame = latest_raw_frame.clone();
        }

        auto detections = detectMotion(raw_frame);
        runTracking(detections, tracked, appearCount, next_id);

        bool has_motion = false;
        for (const auto& [id, tr] : tracked)
        {
            if (appearCount[id] >= 3)  // ìœ íš¨í•œ íŠ¸ë˜í‚¹ ëŒ€ìƒì´ ìˆëŠ”ì§€ í™•ì¸
            {
                has_motion = true;
                break;
            }
        }

        // ë°•ìŠ¤ë§Œ ê·¸ë¦¬ê¸° (ID í‘œì‹œ ì œê±°)
        Mat boxed_frame = raw_frame.clone();
        for (const auto& [id, tr] : tracked)
        {
            if (appearCount[id] < 3) continue;
            rectangle(boxed_frame, tr.box, Scalar(0, 0, 255), 2);
        }

        auto now = steady_clock::now();
        // ğŸ”¥ ìƒˆë¡œ ëª¨ì…˜ì´ ë°œìƒí•œ ê²½ìš°ì—ë§Œ ì´ë¯¸ì§€ ì „ì†¡
        if (has_motion && !prev_had_motion &&
            duration_cast<seconds>(now - ctx->last_snapshot_time).count() >= 10)
        {
            vector<uchar> jpeg_buf;
            vector<int> jpeg_params = {IMWRITE_JPEG_QUALITY, 90};
            imencode(".jpg", boxed_frame, jpeg_buf, jpeg_params);

            send_jsonl_event("intrusion_detected", 1, "intrusion", 1, 0, 0,
                             jpeg_buf.data(), jpeg_buf.size(), ".jpeg");

            ctx->last_snapshot_time = steady_clock::now();
        }

        prev_had_motion = has_motion;

        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
}

